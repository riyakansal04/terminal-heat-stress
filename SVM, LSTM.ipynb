{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6654ca55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall RMSE: 0.062208583752360304\n",
      "Overall R² Score: 0.4829171571617656\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load and clean the data\n",
    "file_path = r\"C:\\Users\\riya kansal\\Desktop\\2016.xlsx\"\n",
    "data = pd.read_excel(file_path)\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Handle missing values\n",
    "data.dropna(subset=['NDVI1', 'MaxTemp1', 'MinTemp1'], inplace=True)\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "# Define the feature columns and target columns for all fortnights\n",
    "feature_columns = []\n",
    "target_columns = []\n",
    "for i in range(1, 9):\n",
    "    feature_columns.extend([\n",
    "        f'MaxTemp{i}', f'MinTemp{i}', \n",
    "        f'DaysMaxTempAbove16{i}', f'DaysMaxTempAbove18{i}', f'DaysMaxTempAbove20{i}', f'DaysMaxTempAbove24{i}',\n",
    "        f'DaysMinTempBelow16{i}', f'DaysMinTempBelow18{i}', f'DaysMinTempBelow20{i}', f'DaysMinTempBelow24{i}',\n",
    "        f'Percentile90_Max{i}', f'Percentile90_Min{i}'\n",
    "    ])\n",
    "    target_columns.append(f'NDVI{i}')\n",
    "\n",
    "# Filter out the available columns in the dataset\n",
    "feature_columns = [col for col in feature_columns if col in data.columns]\n",
    "target_columns = [col for col in target_columns if col in data.columns]\n",
    "\n",
    "# Ensure that we have features and targets\n",
    "if not feature_columns or not target_columns:\n",
    "    raise ValueError(\"No valid features or targets found in the dataset.\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(data[feature_columns])\n",
    "\n",
    "# Dimensionality reduction with PCA (retaining 95% of variance instead of 99%)\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "scaled_features_pca = pca.fit_transform(scaled_features)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features_pca, data[target_columns], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model and hyperparameter grid for SVR\n",
    "base_model = SVR()\n",
    "model = MultiOutputRegressor(base_model)\n",
    "\n",
    "param_dist = {\n",
    "    'estimator__C': [0.1, 1, 10],\n",
    "    'estimator__epsilon': [0.01, 0.1],\n",
    "    'estimator__kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Use RandomizedSearchCV for hyperparameter tuning with fewer iterations\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=5, cv=3, n_jobs=-1, scoring='neg_mean_squared_error', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from RandomizedSearchCV\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate overall metrics for each target\n",
    "overall_rmse = np.sqrt(mean_squared_error(y_test, y_pred, multioutput='raw_values')).mean()\n",
    "overall_r2 = r2_score(y_test, y_pred, multioutput='uniform_average')\n",
    "\n",
    "print(f'Overall RMSE: {overall_rmse}')\n",
    "print(f'Overall R² Score: {overall_r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "161a0da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded. Time taken: 6.84 seconds\n",
      "Handling missing values...\n",
      "Missing values handled. Time taken: 0.03 seconds\n",
      "Defining feature and target columns...\n",
      "Feature and target columns defined. Time taken: 0.00 seconds\n",
      "Scaling features...\n",
      "Features scaled. Time taken: 0.02 seconds\n",
      "Splitting data into training and testing sets...\n",
      "Data split. Time taken: 0.00 seconds\n",
      "Building the LSTM model...\n",
      "LSTM model built. Time taken: 0.12 seconds\n",
      "Training the LSTM model...\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riya kansal\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4567Epoch 1 completed with loss: 2.8357 and val_loss: 0.6898\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 4.4141 - val_loss: 0.6898 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m68/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4509Epoch 2 completed with loss: 0.2776 and val_loss: 0.0823\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4334 - val_loss: 0.0823 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0593Epoch 3 completed with loss: 0.0419 and val_loss: 0.0207\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0577 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0168Epoch 4 completed with loss: 0.0143 and val_loss: 0.0110\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0165 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0102Epoch 5 completed with loss: 0.0094 and val_loss: 0.0090\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0101 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085Epoch 6 completed with loss: 0.0082 and val_loss: 0.0084\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079Epoch 7 completed with loss: 0.0079 and val_loss: 0.0081\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083Epoch 8 completed with loss: 0.0077 and val_loss: 0.0080\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080Epoch 9 completed with loss: 0.0076 and val_loss: 0.0080\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0077Epoch 10 completed with loss: 0.0076 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m62/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0073Epoch 11 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m64/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0075Epoch 12 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075Epoch 13 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m66/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0072Epoch 14 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0076Epoch 15 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0079 - learning_rate: 5.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075Epoch 16 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0079 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074Epoch 17 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: 0.0079 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076Epoch 18 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0079 - learning_rate: 5.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0077Epoch 19 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0077 - val_loss: 0.0079 - learning_rate: 5.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075Epoch 20 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0079 - learning_rate: 2.5000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076Epoch 21 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0079 - learning_rate: 2.5000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074Epoch 22 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: 0.0079 - learning_rate: 2.5000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076Epoch 23 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0079 - learning_rate: 2.5000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m64/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072Epoch 24 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0072 - val_loss: 0.0079 - learning_rate: 2.5000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0074Epoch 25 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0079 - learning_rate: 1.2500e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076Epoch 26 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0079 - learning_rate: 1.2500e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m67/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074Epoch 27 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0079 - learning_rate: 1.2500e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073Epoch 28 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0079 - learning_rate: 1.2500e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m65/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075Epoch 29 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0079 - learning_rate: 1.2500e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074Epoch 30 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: 0.0079 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m70/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075Epoch 31 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0079 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m74/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076Epoch 32 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0079 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075Epoch 33 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0079 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m71/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074Epoch 34 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: 0.0079 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m72/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073Epoch 35 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0079 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m69/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0073Epoch 36 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0079 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076Epoch 37 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0079 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m73/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074Epoch 38 completed with loss: 0.0075 and val_loss: 0.0079\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: 0.0079 - learning_rate: 1.0000e-04\n",
      "Model training completed. Time taken: 21.48 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the LSTM model on the training set...\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Training R² Score: -3.26044791126856e-05\n",
      "Evaluation on training set completed. Time taken: 0.92 seconds\n",
      "Evaluating the LSTM model on the test set...\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "Overall RMSE on Test Set: 0.0870687724769314\n",
      "Overall R² Score on Test Set: -0.00015453103840462612\n",
      "Evaluation on test set completed. Time taken: 0.70 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Bidirectional, BatchNormalization, GRU\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from keras.optimizers import Adam\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the data\n",
    "start_time = time.time()\n",
    "print(\"Loading data...\")\n",
    "file_path = r\"C:\\Users\\riya kansal\\Desktop\\2016.xlsx\"\n",
    "data = pd.read_excel(file_path)\n",
    "data.columns = data.columns.str.strip()\n",
    "print(f\"Data loaded. Time taken: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Handle missing values\n",
    "print(\"Handling missing values...\")\n",
    "start_time = time.time()\n",
    "data.dropna(subset=['NDVI1', 'MaxTemp1', 'MinTemp1'], inplace=True)\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "print(f\"Missing values handled. Time taken: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Define feature and target columns\n",
    "print(\"Defining feature and target columns...\")\n",
    "start_time = time.time()\n",
    "feature_columns = []\n",
    "target_columns = []\n",
    "for i in range(1, 9):\n",
    "    feature_columns.extend([\n",
    "        f'MaxTemp{i}', f'MinTemp{i}', \n",
    "        f'DaysMaxTempAbove16{i}', f'DaysMaxTempAbove18{i}', f'DaysMaxTempAbove20{i}', f'DaysMaxTempAbove24{i}',\n",
    "        f'DaysMinTempBelow16{i}', f'DaysMinTempBelow18{i}', f'DaysMinTempBelow20{i}', f'DaysMinTempBelow24{i}',\n",
    "        f'Percentile90_Max{i}', f'Percentile90_Min{i}'\n",
    "    ])\n",
    "    target_columns.append(f'NDVI{i}')\n",
    "print(f\"Feature and target columns defined. Time taken: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Scale features\n",
    "print(\"Scaling features...\")\n",
    "start_time = time.time()\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(data[feature_columns])\n",
    "X = scaled_features\n",
    "y = data[target_columns].values\n",
    "print(f\"Features scaled. Time taken: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "print(\"Splitting data into training and testing sets...\")\n",
    "start_time = time.time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Data split. Time taken: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Reshape the data for LSTM\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Build the LSTM model with GRU layer and additional regularization\n",
    "print(\"Building the LSTM model...\")\n",
    "start_time = time.time()\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True, activation='relu', kernel_regularizer='l2'), input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(GRU(64, return_sequences=True, activation='relu', kernel_regularizer='l2'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(32, return_sequences=False, activation='relu', kernel_regularizer='l2'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(len(target_columns)))  # Output layer with number of target columns\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "print(f\"LSTM model built. Time taken: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Define callbacks\n",
    "class CustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch + 1} completed with loss: {logs.get('loss'):.4f} and val_loss: {logs.get('val_loss'):.4f}\")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001)\n",
    "custom_callback = CustomCallback()\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the LSTM model...\")\n",
    "start_time = time.time()\n",
    "try:\n",
    "    history = model.fit(X_train_reshaped, y_train, epochs=200, batch_size=64, validation_split=0.2,\n",
    "                        callbacks=[early_stopping, reduce_lr, custom_callback], verbose=1)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "print(f\"Model training completed. Time taken: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "print(\"Evaluating the LSTM model on the training set...\")\n",
    "start_time = time.time()\n",
    "y_train_pred = model.predict(X_train_reshaped)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "print(f'Training R² Score: {train_r2}')\n",
    "print(f\"Evaluation on training set completed. Time taken: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"Evaluating the LSTM model on the test set...\")\n",
    "start_time = time.time()\n",
    "y_test_pred = model.predict(X_test_reshaped)\n",
    "test_rmse = np.sqrt(np.mean((y_test - y_test_pred) ** 2))\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "print(f'Overall RMSE on Test Set: {test_rmse}')\n",
    "print(f'Overall R² Score on Test Set: {test_r2}')\n",
    "print(f\"Evaluation on test set completed. Time taken: {time.time() - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d912054b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
