{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d17c5a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7480 entries, 0 to 7479\n",
      "Columns: 107 entries, YEAR to Percentile90_Min8\n",
      "dtypes: float64(46), int64(61)\n",
      "memory usage: 6.1 MB\n",
      "None\n",
      "YEAR                 0\n",
      "LATITUDE             0\n",
      "LONGITUDE            0\n",
      "NDVI1                0\n",
      "NDVI2                0\n",
      "                    ..\n",
      "Percentile90_Min4    0\n",
      "Percentile90_Min5    0\n",
      "Percentile90_Min6    0\n",
      "Percentile90_Min7    0\n",
      "Percentile90_Min8    0\n",
      "Length: 107, dtype: int64\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Training Mean Squared Error: 0.003594767398394434\n",
      "Training Root Mean Squared Error: 0.05995637913011787\n",
      "Training R² Score: 0.8701129980709474\n",
      "Testing Mean Squared Error: 0.0038493135782567737\n",
      "Testing Root Mean Squared Error: 0.06204283663934761\n",
      "Testing R² Score: 0.860968739167267\n",
      "Testing Predictions:  [0.69681312 0.82334829 0.68462096 0.36955101 0.6548771  0.73600916\n",
      " 0.7859916  0.43496949 0.40117685 0.70927358]\n",
      "Testing Actual values:  [0.65300006 0.80700004 0.72900003 0.40800002 0.51500005 0.73000002\n",
      " 0.81200004 0.44800001 0.46500003 0.76000005]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load and clean the data\n",
    "file_path = r\"C:\\Users\\riya kansal\\Desktop\\2016.xlsx\"  # Update this path to your actual file path\n",
    "data = pd.read_excel(file_path)\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Display dataset information and missing values\n",
    "print(data.info())\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Handling missing values: assuming no rainfall data\n",
    "data.dropna(subset=['NDVI1', 'MaxTemp1', 'MinTemp1'], inplace=True)\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "# Define the number of fortnights\n",
    "num_fortnights = 8\n",
    "\n",
    "# List to store the combined features and targets\n",
    "combined_features = []\n",
    "combined_targets = []\n",
    "\n",
    "# Loop through each fortnight to collect features and targets\n",
    "for i in range(1, num_fortnights + 1):\n",
    "    # Define the features and target for the current fortnight\n",
    "    target = f'NDVI{i}'\n",
    "    features = [f'MaxTemp{i}', f'MinTemp{i}', f'DaysMaxTempAbove16{i}',\n",
    "                f'DaysMaxTempAbove18{i}', f'DaysMaxTempAbove20{i}', f'DaysMaxTempAbove24{i}',\n",
    "                f'DaysMinTempBelow16{i}', f'DaysMinTempBelow18{i}', f'DaysMinTempBelow20{i}',\n",
    "                f'DaysMinTempBelow24{i}', f'Percentile99_Max{i}', f'Percentile95_Max{i}',\n",
    "                f'Percentile90_Max{i}', f'Percentile99_Min{i}', f'Percentile95_Min{i}',\n",
    "                f'Percentile90_Min{i}']\n",
    "\n",
    "    # Ensure the features exist in the dataset\n",
    "    features = [feature for feature in features if feature in data.columns]\n",
    "\n",
    "    # Collect features and targets for the current fortnight\n",
    "    if features and target in data.columns:\n",
    "        combined_features.append(data[features])\n",
    "        combined_targets.append(data[target])\n",
    "\n",
    "# Concatenate all features and targets\n",
    "X = pd.concat(combined_features, axis=0)\n",
    "y = pd.concat(combined_targets, axis=0)\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the Gradient Boosting model\n",
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Grid search for the best parameters\n",
    "grid_search = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_gbr = grid_search.best_estimator_\n",
    "\n",
    "# Predict and evaluate\n",
    "y_train_pred = best_gbr.predict(X_train)\n",
    "y_test_pred = best_gbr.predict(X_test)\n",
    "\n",
    "# Training set evaluation\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(f'Training Mean Squared Error: {train_mse}')\n",
    "print(f'Training Root Mean Squared Error: {train_rmse}')\n",
    "print(f'Training R² Score: {train_r2}')\n",
    "\n",
    "# Testing set evaluation\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Testing Mean Squared Error: {test_mse}')\n",
    "print(f'Testing Root Mean Squared Error: {test_rmse}')\n",
    "print(f'Testing R² Score: {test_r2}')\n",
    "\n",
    "# Output the predictions and actual values for further analysis\n",
    "print(\"Testing Predictions: \", y_test_pred[:10])\n",
    "print(\"Testing Actual values: \", y_test[:10].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f309206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
